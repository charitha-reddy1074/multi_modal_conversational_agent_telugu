{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~qdm (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~qdm (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~qdm (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26adfae1b89043249123e8191159d95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ö‡∞æ‡∞ü‡±ç ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡±Å</h2>\"), HBox(children=(Text(value=''‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Telugu Chatbot with Live Voice Recording and Generative AI\n",
    "!pip install -q transformers torch langid sounddevice numpy scipy ipywidgets\n",
    "!apt-get install -qq libportaudio2\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from langid import classify\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import re\n",
    "from IPython.display import display, Audio, clear_output\n",
    "import ipywidgets as widgets\n",
    "import queue\n",
    "import threading\n",
    "\n",
    "# Initialize with CPU support\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load models\n",
    "try:\n",
    "    print(\"Loading models...\")\n",
    "    # Using a more capable model for Telugu\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\").to(device)\n",
    "    asr = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-tiny\", device=device)\n",
    "    print(\"Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    raise RuntimeError(\"Failed to load models\")\n",
    "\n",
    "# Telugu knowledge base (now used as examples for the generative model)\n",
    "telugu_examples = {\n",
    "    \"general\": [\n",
    "        {\"input\": \"‡∞π‡∞≤‡±ã\", \"response\": \"‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç! ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞≤‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å?\"},\n",
    "        {\"input\": \"‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å\", \"response\": \"‡∞∏‡±ç‡∞µ‡∞æ‡∞ó‡∞§‡∞Ç! ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞á‡∞Ç‡∞ï‡±á‡∞Æ‡±à‡∞®‡∞æ ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞ï‡∞æ‡∞µ‡∞æ‡∞≤‡∞æ?\"},\n",
    "        {\"input\": \"‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ‡∞∞‡±ç‡∞•‡±Å‡∞≤‡∞ï‡±Å ‡∞∏‡∞≤‡∞π‡∞æ‡∞≤‡±Å\", \"response\": \"‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ‡∞∞‡±ç‡∞•‡±Å‡∞≤‡±Å‡∞ó‡∞æ ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞®‡∞ø‡∞Ø‡∞Æ‡∞ø‡∞§ ‡∞∏‡∞Æ‡∞Ø ‡∞™‡∞ü‡±ç‡∞ü‡∞ø‡∞ï‡∞®‡±Å ‡∞™‡∞æ‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞∞‡±ã‡∞ú‡±Å‡∞µ‡∞æ‡∞∞‡±Ä ‡∞Ö‡∞≠‡±ç‡∞Ø‡∞æ‡∞∏‡∞Ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡∞∞‡±à‡∞® ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø‡∞ï‡∞∞‡∞Æ‡±à‡∞® ‡∞Ü‡∞π‡∞æ‡∞∞‡∞Ç ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø.\"}\n",
    "    ],\n",
    "    \"facts\": {\n",
    "        \"‡∞§‡∞ø‡∞∞‡±Å‡∞™‡∞§‡∞ø ‡∞Ü‡∞≤‡∞Ø‡∞Ç\": \"‡∞§‡∞ø‡∞∞‡±Å‡∞™‡∞§‡∞ø‡∞≤‡±ã‡∞®‡∞ø ‡∞∂‡±ç‡∞∞‡±Ä ‡∞µ‡±á‡∞Ç‡∞ï‡∞ü‡±á‡∞∂‡±ç‡∞µ‡∞∞ ‡∞∏‡±ç‡∞µ‡∞æ‡∞Æ‡∞ø ‡∞Ü‡∞≤‡∞Ø‡∞Ç ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂‡∞Ç‡∞≤‡±ã ‡∞Ö‡∞§‡±ç‡∞Ø‡∞Ç‡∞§ ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß ‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞æ‡∞≤‡∞≤‡±ã ‡∞í‡∞ï‡∞ü‡∞ø.\",\n",
    "        \"‡∞ö‡∞æ‡∞∞‡±ç‡∞Æ‡∞ø‡∞®‡∞æ‡∞∞‡±ç\": \"‡∞π‡±à‡∞¶‡∞∞‡∞æ‡∞¨‡∞æ‡∞¶‡±ç ‡∞≤‡±ã‡∞®‡∞ø ‡∞ö‡∞æ‡∞∞‡±ç‡∞Æ‡∞ø‡∞®‡∞æ‡∞∞‡±ç ‡∞í‡∞ï ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß ‡∞ö‡∞æ‡∞∞‡∞ø‡∞§‡±ç‡∞∞‡∞ï ‡∞∏‡±ç‡∞Æ‡∞æ‡∞∞‡∞ï‡∞Ç.\",\n",
    "        \"‡∞ó‡±ã‡∞≤‡±ç‡∞ï‡±ä‡∞Ç‡∞° ‡∞ï‡±ã‡∞ü\": \"‡∞ó‡±ã‡∞≤‡±ç‡∞ï‡±ä‡∞Ç‡∞° ‡∞ï‡±ã‡∞ü ‡∞π‡±à‡∞¶‡∞∞‡∞æ‡∞¨‡∞æ‡∞¶‡±ç ‡∞®‡∞ó‡∞∞‡∞Ç ‡∞∏‡∞Æ‡±Ä‡∞™‡∞Ç‡∞≤‡±ã ‡∞â‡∞Ç‡∞¶‡∞ø.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def clean_telugu_text(text):\n",
    "    \"\"\"Clean and format Telugu text output\"\"\"\n",
    "    # Remove special tokens and extra spaces\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Ensure proper Telugu punctuation\n",
    "    text = text.replace(' .', '‡•§').replace('.', '‡•§')\n",
    "    return text\n",
    "\n",
    "def generate_telugu_response(user_input, chat_history=\"\"):\n",
    "    \"\"\"Generate natural Telugu responses using the model\"\"\"\n",
    "    # Check if it's a factual question first\n",
    "    for keyword, response in telugu_examples[\"facts\"].items():\n",
    "        if keyword in user_input:\n",
    "            return response\n",
    "    \n",
    "    # Prepare context for generative response\n",
    "    context = \"‡∞Æ‡±Ä‡∞∞‡±Å ‡∞í‡∞ï ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡∞ø‡∞ó‡∞æ ‡∞™‡±ç‡∞∞‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø. ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡∞ø‡∞ó‡∞æ ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞∏‡∞π‡∞ú‡∞Æ‡±à‡∞®, ‡∞∏‡±ç‡∞®‡±á‡∞π‡∞™‡±Ç‡∞∞‡±ç‡∞µ‡∞ï‡∞Æ‡±à‡∞® ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡∞ø‡∞µ‡∞∞‡∞£‡∞æ‡∞§‡±ç‡∞Æ‡∞ï‡∞Æ‡±à‡∞® ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞æ‡∞≤‡∞®‡±Å ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø.\\n\"\n",
    "    \n",
    "    # Add example conversations\n",
    "    for example in telugu_examples[\"general\"]:\n",
    "        context += f\"User: {example['input']}\\nAssistant: {example['response']}\\n\"\n",
    "    \n",
    "    # Add current conversation history\n",
    "    if chat_history:\n",
    "        context += chat_history + \"\\n\"\n",
    "    \n",
    "    # Add current user input\n",
    "    prompt = context + f\"User: {user_input}\\nAssistant:\"\n",
    "    \n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            num_beams=5,\n",
    "            temperature=0.8,\n",
    "            top_p=0.95,\n",
    "            do_sample=True,\n",
    "            no_repeat_ngram_size=3,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract only the assistant's response\n",
    "        if \"Assistant:\" in response:\n",
    "            response = response.split(\"Assistant:\")[-1].strip()\n",
    "        \n",
    "        return clean_telugu_text(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Generation error: {e}\")\n",
    "        return \"‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞è‡∞∞‡±ç‡∞™‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.\"\n",
    "\n",
    "# Audio recording variables\n",
    "audio_queue = queue.Queue()\n",
    "is_recording = False\n",
    "sample_rate = 16000\n",
    "audio_data = []\n",
    "\n",
    "# Create Jupyter widgets\n",
    "output_area = widgets.Output()\n",
    "chat_history = widgets.HTML(value=\"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ö‡∞æ‡∞ü‡±ç ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡±Å</h2>\")\n",
    "input_text = widgets.Text(placeholder='‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞ü‡±à‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø...', layout=widgets.Layout(width='80%'))\n",
    "send_button = widgets.Button(description='‡∞™‡∞Ç‡∞™‡∞ø‡∞Ç‡∞ö‡±Å', button_style='success', icon='send')\n",
    "start_button = widgets.Button(description='‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø üé§', button_style='info')\n",
    "stop_button = widgets.Button(description='‡∞®‡∞ø‡∞≤‡±Å‡∞™‡±Å ‚èπÔ∏è', button_style='danger', disabled=True)\n",
    "clear_button = widgets.Button(description='‡∞ï‡±ä‡∞§‡±ç‡∞§‡∞ó‡∞æ ‡∞Æ‡±ä‡∞¶‡∞≤‡±Å‡∞™‡±Ü‡∞ü‡±ç‡∞ü‡±Å', button_style='warning')\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"Called for each audio block when recording\"\"\"\n",
    "    if is_recording:\n",
    "        audio_data.append(indata.copy())\n",
    "\n",
    "def start_recording(b):\n",
    "    \"\"\"Start live audio recording\"\"\"\n",
    "    global is_recording, audio_data\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        print(\"‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡±Å‡∞§‡±Ç ‡∞â‡∞Ç‡∞°‡∞Ç‡∞°‡∞ø... (3 ‡∞∏‡±Ü‡∞ï‡∞®‡±ç‡∞≤ ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§ ‡∞®‡∞ø‡∞≤‡±Å‡∞™‡±Å‡∞Æ‡∞®‡∞ø ‡∞®‡±ä‡∞ï‡±ç‡∞ï‡∞Ç‡∞°‡∞ø)\")\n",
    "        is_recording = True\n",
    "        audio_data = []\n",
    "        start_button.disabled = True\n",
    "        stop_button.disabled = False\n",
    "        sd.InputStream(samplerate=sample_rate, channels=1, callback=audio_callback).start()\n",
    "\n",
    "def stop_recording(b):\n",
    "    \"\"\"Stop recording and process audio\"\"\"\n",
    "    global is_recording\n",
    "    is_recording = False\n",
    "    start_button.disabled = False\n",
    "    stop_button.disabled = True\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        if len(audio_data) > 0:\n",
    "            # Save and play recorded audio\n",
    "            recording = np.concatenate(audio_data)\n",
    "            wav.write(\"user_audio.wav\", sample_rate, recording)\n",
    "            display(Audio(\"user_audio.wav\", rate=sample_rate))\n",
    "            \n",
    "            # Transcribe audio\n",
    "            try:\n",
    "                user_input = asr(\"user_audio.wav\")['text']\n",
    "                input_text.value = user_input\n",
    "                print(f\"‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞∞‡±Å: {user_input}\")\n",
    "                # Automatically send the voice input\n",
    "                on_send(None)\n",
    "            except Exception as e:\n",
    "                print(f\"‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç‡∞≤‡±ã ‡∞≤‡±ã‡∞™‡∞Ç: {e}\")\n",
    "        else:\n",
    "            print(\"‡∞è ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞∞‡∞ø‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞≤‡±á‡∞¶‡±Å\")\n",
    "\n",
    "def on_send(b):\n",
    "    \"\"\"Handle text/voice input and generate response\"\"\"\n",
    "    user_input = input_text.value.strip()\n",
    "    if not user_input:\n",
    "        return\n",
    "        \n",
    "    # Add user message to chat\n",
    "    chat_history.value += f\"<div style='background:#eaf2f8;padding:10px;margin:5px;border-radius:5px'><b>‡∞Æ‡±Ä‡∞∞‡±Å:</b> {user_input}</div>\"\n",
    "    input_text.value = ''\n",
    "    \n",
    "    # Generate and display response\n",
    "    with output_area:\n",
    "        print(\"‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞∏‡±ç‡∞™‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Æ‡±Å...\")\n",
    "        response = generate_telugu_response(user_input, chat_history.value)\n",
    "        chat_history.value += f\"<div style='background:#e8f8f5;padding:10px;margin:5px;border-radius:5px'><b>‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡±Å:</b> {response}</div>\"\n",
    "        clear_output()\n",
    "\n",
    "def on_clear(b):\n",
    "    \"\"\"Clear conversation history\"\"\"\n",
    "    chat_history.value = \"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ö‡∞æ‡∞ü‡±ç ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡±Å</h2>\"\n",
    "    input_text.value = ''\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "\n",
    "# Set up button actions\n",
    "start_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "send_button.on_click(on_send)\n",
    "clear_button.on_click(on_clear)\n",
    "\n",
    "# Display the interface\n",
    "display(widgets.VBox([\n",
    "    chat_history,\n",
    "    widgets.HBox([input_text, send_button]),\n",
    "    widgets.HBox([start_button, stop_button, clear_button]),\n",
    "    output_area\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~qdm (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~qdm (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~qdm (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d954314fb7ca4b7784238966424dc67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡∞ø‡∞µ‡±ç ‡∞ö‡∞æ‡∞ü‡±ç\\u200c‡∞¨‡∞æ‡∞ü‡±ç</h2>\"), HBox(children=(Tex‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fully Generative Telugu Chatbot with Voice Input\n",
    "!pip install -q transformers torch langid sounddevice numpy scipy ipywidgets ffmpeg-python\n",
    "!apt-get install -qq libportaudio2 ffmpeg\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from IPython.display import display, Audio, clear_output\n",
    "import ipywidgets as widgets\n",
    "import ffmpeg\n",
    "import re\n",
    "\n",
    "# Initialize with CPU/GPU support\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "try:\n",
    "    # Using a model better suited for Telugu generation\n",
    "    model_name = \"microsoft/DialoGPT-medium\"  # Can replace with Telugu-specific model if available\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "    \n",
    "    # Speech recognition model\n",
    "    asr = pipeline(\"automatic-speech-recognition\", \n",
    "                  model=\"openai/whisper-small\",  # Using small for better Telugu recognition\n",
    "                  device=device,\n",
    "                  chunk_length_s=30,\n",
    "                  stride_length_s=5)\n",
    "    print(\"Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    raise RuntimeError(\"Failed to load models\")\n",
    "\n",
    "# Audio recording variables\n",
    "is_recording = False\n",
    "sample_rate = 16000\n",
    "audio_data = []\n",
    "\n",
    "def save_audio_to_wav(audio_np_array, filename=\"user_audio.wav\"):\n",
    "    \"\"\"Save numpy array as WAV file with proper FFmpeg conversion\"\"\"\n",
    "    try:\n",
    "        # First save as temporary raw file\n",
    "        temp_file = \"temp.raw\"\n",
    "        wav.write(temp_file, sample_rate, audio_np_array)\n",
    "        \n",
    "        # Convert to proper WAV format using FFmpeg\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(temp_file, format='s16le', ac=1, ar=sample_rate)\n",
    "            .output(filename, format='wav')\n",
    "            .overwrite_output()\n",
    "            .run(quiet=True)\n",
    "        )\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"Audio save error: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    \"\"\"Transcribe audio with error handling\"\"\"\n",
    "    try:\n",
    "        result = asr(audio_file)\n",
    "        return result['text']\n",
    "    except Exception as e:\n",
    "        print(f\"Transcription error: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_telugu_response(user_input, chat_history=\"\"):\n",
    "    \"\"\"Generate natural Telugu responses using the model\"\"\"\n",
    "    # Prepare context for generative response\n",
    "    context = (\n",
    "        \"‡∞Æ‡±Ä‡∞∞‡±Å ‡∞í‡∞ï ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡∞ø‡∞ó‡∞æ ‡∞™‡±ç‡∞∞‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø. ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞∏‡∞π‡∞ú‡∞Æ‡±à‡∞®, ‡∞∏‡±ç‡∞®‡±á‡∞π‡∞™‡±Ç‡∞∞‡±ç‡∞µ‡∞ï‡∞Æ‡±à‡∞® ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡∞ø‡∞µ‡∞∞‡∞£‡∞æ‡∞§‡±ç‡∞Æ‡∞ï‡∞Æ‡±à‡∞® ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞æ‡∞≤‡∞®‡±Å ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø.\\n\"\n",
    "        \"‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£:\\n\"\n",
    "        \"User: ‡∞π‡∞≤‡±ã\\n\"\n",
    "        \"Assistant: ‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç! ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞≤‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å? ‡∞è‡∞Æ‡±à‡∞®‡∞æ ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞ï‡∞æ‡∞µ‡∞æ‡∞≤‡∞æ?\\n\"\n",
    "        \"User: ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡±Å\\n\"\n",
    "        \"Assistant: ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞í‡∞ï ‡∞∏‡±Å‡∞Ç‡∞¶‡∞∞‡∞Æ‡±à‡∞® ‡∞≠‡∞æ‡∞∑, ‡∞á‡∞¶‡∞ø ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂‡∞Ç‡∞≤‡±ã ‡∞Ö‡∞ß‡∞ø‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡±á ‡∞≠‡∞æ‡∞∑‡∞≤‡∞≤‡±ã ‡∞í‡∞ï‡∞ü‡∞ø. ‡∞¶‡±Ä‡∞®‡∞ø‡∞®‡∞ø '‡∞á‡∞ü‡∞æ‡∞≤‡±Ä ‡∞Ü‡∞´‡±ç ‡∞¶‡∞ø ‡∞à‡∞∏‡±ç‡∞ü‡±ç' ‡∞Ö‡∞®‡∞ø ‡∞ï‡±Ç‡∞°‡∞æ ‡∞™‡∞ø‡∞≤‡±Å‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å.\\n\"\n",
    "    )\n",
    "    \n",
    "    # Add conversation history if available\n",
    "    if chat_history:\n",
    "        context += f\"\\n{chat_history}\\n\"\n",
    "    \n",
    "    # Add current user input\n",
    "    prompt = context + f\"User: {user_input}\\nAssistant:\"\n",
    "    \n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            num_beams=5,\n",
    "            temperature=0.8,\n",
    "            top_p=0.95,\n",
    "            do_sample=True,\n",
    "            no_repeat_ngram_size=3,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract only the assistant's response\n",
    "        if \"Assistant:\" in response:\n",
    "            response = response.split(\"Assistant:\")[-1].strip()\n",
    "        \n",
    "        return clean_telugu_text(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Generation error: {e}\")\n",
    "        return \"‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞è‡∞∞‡±ç‡∞™‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.\"\n",
    "\n",
    "def clean_telugu_text(text):\n",
    "    \"\"\"Clean and format Telugu text output\"\"\"\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Remove any HTML tags\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    text = text.replace(' .', '‡•§').replace('.', '‡•§')  # Proper Telugu punctuation\n",
    "    return text\n",
    "\n",
    "# Create Jupyter widgets\n",
    "output_area = widgets.Output()\n",
    "chat_history = widgets.HTML(value=\"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡∞ø‡∞µ‡±ç ‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç</h2>\")\n",
    "input_text = widgets.Text(placeholder='‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞ü‡±à‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø...', layout=widgets.Layout(width='80%'))\n",
    "send_button = widgets.Button(description='‡∞™‡∞Ç‡∞™‡∞ø‡∞Ç‡∞ö‡±Å', button_style='success', icon='send')\n",
    "start_button = widgets.Button(description='‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø üé§', button_style='info')\n",
    "stop_button = widgets.Button(description='‡∞®‡∞ø‡∞≤‡±Å‡∞™‡±Å ‚èπÔ∏è', button_style='danger', disabled=True)\n",
    "clear_button = widgets.Button(description='‡∞ï‡±ä‡∞§‡±ç‡∞§‡∞ó‡∞æ ‡∞Æ‡±ä‡∞¶‡∞≤‡±Å‡∞™‡±Ü‡∞ü‡±ç‡∞ü‡±Å', button_style='warning')\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"Called for each audio block when recording\"\"\"\n",
    "    if is_recording:\n",
    "        audio_data.append(indata.copy())\n",
    "\n",
    "def start_recording(b):\n",
    "    \"\"\"Start live audio recording\"\"\"\n",
    "    global is_recording, audio_data\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        print(\"‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡±Å‡∞§‡±Ç ‡∞â‡∞Ç‡∞°‡∞Ç‡∞°‡∞ø... (3-5 ‡∞∏‡±Ü‡∞ï‡∞®‡±ç‡∞≤ ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§ ‡∞®‡∞ø‡∞≤‡±Å‡∞™‡±Å‡∞Æ‡∞®‡∞ø ‡∞®‡±ä‡∞ï‡±ç‡∞ï‡∞Ç‡∞°‡∞ø)\")\n",
    "        is_recording = True\n",
    "        audio_data = []\n",
    "        start_button.disabled = True\n",
    "        stop_button.disabled = False\n",
    "        sd.InputStream(samplerate=sample_rate, channels=1, callback=audio_callback).start()\n",
    "\n",
    "def stop_recording(b):\n",
    "    \"\"\"Stop recording and process audio\"\"\"\n",
    "    global is_recording\n",
    "    is_recording = False\n",
    "    start_button.disabled = False\n",
    "    stop_button.disabled = True\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        if len(audio_data) > 0:\n",
    "            try:\n",
    "                # Convert audio data to numpy array\n",
    "                recording = np.concatenate(audio_data)\n",
    "                \n",
    "                # Save audio with proper format conversion\n",
    "                audio_file = save_audio_to_wav(recording)\n",
    "                if not audio_file:\n",
    "                    raise ValueError(\"Audio file could not be saved\")\n",
    "                \n",
    "                # Play back the recording\n",
    "                display(Audio(audio_file, rate=sample_rate))\n",
    "                \n",
    "                # Transcribe audio\n",
    "                user_input = transcribe_audio(audio_file)\n",
    "                if user_input:\n",
    "                    input_text.value = user_input\n",
    "                    print(f\"‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞∞‡±Å: {user_input}\")\n",
    "                    # Automatically send the transcribed text\n",
    "                    on_send(None)\n",
    "                else:\n",
    "                    print(\"‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç‡∞≤‡±ã ‡∞≤‡±ã‡∞™‡∞Ç. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.\")\n",
    "            except Exception as e:\n",
    "                print(f\"‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞≤‡±ã‡∞™‡∞Ç: {e}\")\n",
    "        else:\n",
    "            print(\"‡∞è ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞∞‡∞ø‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞≤‡±á‡∞¶‡±Å\")\n",
    "\n",
    "def on_send(b):\n",
    "    \"\"\"Handle text/voice input and generate response\"\"\"\n",
    "    user_input = input_text.value.strip()\n",
    "    if not user_input:\n",
    "        return\n",
    "        \n",
    "    # Add user message to chat\n",
    "    chat_history.value += f\"<div style='background:#eaf2f8;padding:10px;margin:5px;border-radius:5px'><b>‡∞Æ‡±Ä‡∞∞‡±Å:</b> {user_input}</div>\"\n",
    "    input_text.value = ''\n",
    "    \n",
    "    # Generate and display response\n",
    "    with output_area:\n",
    "        print(\"‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞∏‡±ç‡∞™‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Æ‡±Å...\")\n",
    "        response = generate_telugu_response(user_input, chat_history.value)\n",
    "        chat_history.value += f\"<div style='background:#e8f8f5;padding:10px;margin:5px;border-radius:5px'><b>‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡±Å:</b> {response}</div>\"\n",
    "        clear_output()\n",
    "\n",
    "def on_clear(b):\n",
    "    \"\"\"Clear conversation history\"\"\"\n",
    "    chat_history.value = \"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡∞ø‡∞µ‡±ç ‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç</h2>\"\n",
    "    input_text.value = ''\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "\n",
    "# Set up button actions\n",
    "start_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "send_button.on_click(on_send)\n",
    "clear_button.on_click(on_clear)\n",
    "\n",
    "# Display the interface\n",
    "display(widgets.VBox([\n",
    "    chat_history,\n",
    "    widgets.HBox([input_text, send_button]),\n",
    "    widgets.HBox([start_button, stop_button, clear_button]),\n",
    "    output_area\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~qdm (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~qdm (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~qdm (C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading models...\n",
      "Models loaded successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04621a836e6748809858baa049b9dce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ö‡∞æ‡∞ü‡±ç\\u200c‡∞¨‡∞æ‡∞ü‡±ç</h2>\"), HBox(children=(Text(value='‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø! ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡±Å ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø.\n"
     ]
    }
   ],
   "source": [
    "# Telugu Text Chatbot with Knowledge Base\n",
    "!pip install -q transformers torch ipywidgets\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "\n",
    "# Initialize device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\").to(device)\n",
    "    print(\"Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    raise\n",
    "\n",
    "# Telugu Knowledge Base for Indian Places\n",
    "knowledge_base = {\n",
    "    # Temples\n",
    "    \"‡∞§‡∞ø‡∞∞‡±Å‡∞™‡∞§‡∞ø\": {\n",
    "        \"description\": (\"‡∞§‡∞ø‡∞∞‡±Å‡∞™‡∞§‡∞ø‡∞≤‡±ã‡∞®‡∞ø ‡∞∂‡±ç‡∞∞‡±Ä ‡∞µ‡±á‡∞Ç‡∞ï‡∞ü‡±á‡∞∂‡±ç‡∞µ‡∞∞ ‡∞∏‡±ç‡∞µ‡∞æ‡∞Æ‡∞ø ‡∞Ü‡∞≤‡∞Ø‡∞Ç ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß ‡∞π‡∞ø‡∞Ç‡∞¶‡±Ç ‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞Ç. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞Ü‡∞Ç‡∞ß‡±ç‡∞∞‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡±ç ‡∞≤‡±ã‡∞®‡∞ø ‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤ ‡∞™‡∞∞‡±ç‡∞µ‡∞§‡∞æ‡∞≤ ‡∞Æ‡±Ä‡∞¶ ‡∞â‡∞Ç‡∞¶‡∞ø. \"\n",
    "                      \"‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞∏‡∞Ç‡∞µ‡∞§‡±ç‡∞∏‡∞∞‡∞Ç ‡∞≤‡∞ï‡±ç‡∞∑‡∞≤‡∞æ‡∞¶‡∞ø ‡∞≠‡∞ï‡±ç‡∞§‡±Å‡∞≤‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ï‡±Å ‡∞¶‡∞∞‡±ç‡∞∂‡∞®‡∞Ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞µ‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å.\"),\n",
    "        \"tags\": [\"‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤\", \"‡∞µ‡±á‡∞Ç‡∞ï‡∞ü‡±á‡∞∂‡±ç‡∞µ‡∞∞\", \"‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞Ç\"]\n",
    "    },\n",
    "    \"‡∞µ‡∞æ‡∞∞‡∞£‡∞æ‡∞∏‡∞ø\": {\n",
    "        \"description\": (\"‡∞µ‡∞æ‡∞∞‡∞£‡∞æ‡∞∏‡∞ø (‡∞ï‡∞æ‡∞∂‡±Ä) ‡∞ó‡∞Ç‡∞ó‡∞æ ‡∞®‡∞¶‡∞ø ‡∞í‡∞°‡±ç‡∞°‡±Å‡∞® ‡∞â‡∞®‡±ç‡∞® ‡∞™‡±Å‡∞£‡±ç‡∞Ø‡∞®‡∞ó‡∞∞‡∞Ç. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞™‡±ç‡∞∞‡∞™‡∞Ç‡∞ö‡∞Ç‡∞≤‡±ã‡∞®‡±á ‡∞Ö‡∞§‡±ç‡∞Ø‡∞Ç‡∞§ ‡∞™‡±Å‡∞∞‡∞æ‡∞§‡∞® ‡∞®‡∞ó‡∞∞‡∞æ‡∞≤‡∞≤‡±ã ‡∞í‡∞ï‡∞ü‡∞ø. \"\n",
    "                      \"‡∞ï‡∞æ‡∞∂‡±Ä ‡∞µ‡∞ø‡∞∂‡±ç‡∞µ‡∞®‡∞æ‡∞•‡±ç ‡∞¶‡±á‡∞µ‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞Ç ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£.\"),\n",
    "        \"tags\": [\"‡∞ï‡∞æ‡∞∂‡±Ä\", \"‡∞ó‡∞Ç‡∞ó‡∞æ\", \"‡∞µ‡∞ø‡∞∂‡±ç‡∞µ‡∞®‡∞æ‡∞•‡±ç\"]\n",
    "    },\n",
    "    \n",
    "    # Historical Sites\n",
    "    \"‡∞§‡∞æ‡∞ú‡±ç ‡∞Æ‡∞π‡∞≤‡±ç\": {\n",
    "        \"description\": (\"‡∞§‡∞æ‡∞ú‡±ç ‡∞Æ‡∞π‡∞≤‡±ç ‡∞â‡∞§‡±ç‡∞§‡∞∞‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡±ç ‡∞≤‡±ã‡∞®‡∞ø ‡∞Ü‡∞ó‡±ç‡∞∞‡∞æ‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® ‡∞™‡∞æ‡∞≤‡∞∞‡∞æ‡∞Ø‡∞ø ‡∞Æ‡∞ï‡±ç‡∞¨‡∞∞‡∞æ. \"\n",
    "                      \"‡∞Æ‡±ä‡∞ò‡∞≤‡±ç ‡∞ö‡∞ï‡±ç‡∞∞‡∞µ‡∞∞‡±ç‡∞§‡∞ø ‡∞∑‡∞æ‡∞ú‡∞π‡∞æ‡∞®‡±ç ‡∞§‡∞® ‡∞≠‡∞æ‡∞∞‡±ç‡∞Ø ‡∞Æ‡±Å‡∞Æ‡±ç‡∞§‡∞æ‡∞ú‡±ç ‡∞Æ‡∞π‡∞≤‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞æ‡∞∞‡±Å. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞™‡±ç‡∞∞‡∞™‡∞Ç‡∞ö ‡∞è‡∞°‡±Å ‡∞Ö‡∞¶‡±ç‡∞≠‡±Å‡∞§‡∞æ‡∞≤‡∞≤‡±ã ‡∞í‡∞ï‡∞ü‡∞ø‡∞ó‡∞æ ‡∞™‡∞∞‡∞ø‡∞ó‡∞£‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.\"),\n",
    "        \"tags\": [\"‡∞Ü‡∞ó‡±ç‡∞∞‡∞æ\", \"‡∞Æ‡±ä‡∞ò‡∞≤‡±ç\", \"‡∞™‡±ç‡∞∞‡±á‡∞Æ ‡∞∏‡±ç‡∞Æ‡∞æ‡∞∞‡∞ï‡∞Ç\"]\n",
    "    },\n",
    "    \"‡∞¢‡∞ø‡∞≤‡±ç‡∞≤‡±Ä\": {\n",
    "        \"description\": (\"‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂ ‡∞∞‡∞æ‡∞ú‡∞ß‡∞æ‡∞®‡∞ø ‡∞¢‡∞ø‡∞≤‡±ç‡∞≤‡±Ä ‡∞ö‡∞æ‡∞∞‡∞ø‡∞§‡±ç‡∞∞‡∞ï ‡∞™‡±ç‡∞∞‡∞æ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞§ ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø‡∞® ‡∞®‡∞ó‡∞∞‡∞Ç. \"\n",
    "                      \"‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞é‡∞∞‡±ç‡∞∞‡∞ï‡±ã‡∞ü, ‡∞ï‡±Å‡∞§‡±Å‡∞¨‡±ç ‡∞Æ‡∞ø‡∞®‡∞æ‡∞∞‡±ç, ‡∞≤‡±ã‡∞ü‡∞∏‡±ç ‡∞ü‡±Ü‡∞Ç‡∞™‡±Å‡∞≤‡±ç ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß ‡∞∏‡±ç‡∞Æ‡∞æ‡∞∞‡∞ï‡∞æ‡∞≤‡±Å ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞¶‡±á‡∞∂‡∞Ç ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞∞‡∞æ‡∞ú‡∞ï‡±Ä‡∞Ø, ‡∞∏‡∞æ‡∞Ç‡∞∏‡±ç‡∞ï‡±É‡∞§‡∞ø‡∞ï ‡∞ï‡±á‡∞Ç‡∞¶‡±ç‡∞∞‡∞Ç.\"),\n",
    "        \"tags\": [\"‡∞∞‡∞æ‡∞ú‡∞ß‡∞æ‡∞®‡∞ø\", \"‡∞é‡∞∞‡±ç‡∞∞‡∞ï‡±ã‡∞ü\", \"‡∞ï‡±Å‡∞§‡±Å‡∞¨‡±ç ‡∞Æ‡∞ø‡∞®‡∞æ‡∞∞‡±ç\"]\n",
    "    },\n",
    "    \n",
    "    # Natural Wonders\n",
    "    \"‡∞ï‡±á‡∞∞‡∞≥\": {\n",
    "        \"description\": (\"‡∞ï‡±á‡∞∞‡∞≥‡∞®‡±Å '‡∞¶‡±á‡∞µ‡±Å‡∞®‡∞ø ‡∞∏‡±ç‡∞µ‡∞Ç‡∞§ ‡∞®‡∞æ‡∞°‡±Å' ‡∞Ö‡∞®‡∞ø ‡∞™‡∞ø‡∞≤‡±Å‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å. \"\n",
    "                      \"‡∞¨‡±ç‡∞Ø‡∞æ‡∞ï‡±ç ‡∞µ‡∞æ‡∞ü‡∞∞‡±ç‡∞∏‡±ç, ‡∞ï‡±ä‡∞ï‡±ç‡∞ï‡±ã‡∞®‡∞ü‡±ç ‡∞¨‡±Ä‡∞ö‡±ç‚Äå‡∞≤‡±Å, ‡∞Ö‡∞°‡∞µ‡±Å‡∞≤‡±Å, ‡∞Ü‡∞Ø‡±Å‡∞∞‡±ç‡∞µ‡±á‡∞¶‡∞Ç ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞§‡±ç‡∞Ø‡±á‡∞ï‡∞§‡∞≤‡±Å. \"\n",
    "                      \"‡∞Æ‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±ç, ‡∞Ö‡∞≤‡±ç‡∞≤‡±Ü‡∞™‡±ç‡∞™‡±Ä, ‡∞ï‡±ä‡∞ö‡±ç‡∞ö‡∞ø ‡∞™‡±ç‡∞∞‡∞Æ‡±Å‡∞ñ ‡∞™‡∞∞‡±ç‡∞Ø‡∞æ‡∞ü‡∞ï ‡∞∏‡±ç‡∞•‡∞≤‡∞æ‡∞≤‡±Å.\"),\n",
    "        \"tags\": [\"‡∞¨‡±ç‡∞Ø‡∞æ‡∞ï‡±ç ‡∞µ‡∞æ‡∞ü‡∞∞‡±ç‡∞∏‡±ç\", \"‡∞Æ‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±ç\", \"‡∞Ü‡∞Ø‡±Å‡∞∞‡±ç‡∞µ‡±á‡∞¶‡∞Ç\"]\n",
    "    },\n",
    "    \"‡∞≤‡∞°‡∞ñ‡±ç\": {\n",
    "        \"description\": (\"‡∞≤‡∞°‡∞ñ‡±ç ‡∞π‡∞ø‡∞Æ‡∞æ‡∞≤‡∞Ø‡∞æ‡∞≤‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® ‡∞í‡∞ï ‡∞∂‡±Ä‡∞§‡∞≤ ‡∞Æ‡∞∞‡±Å‡∞≠‡±Ç‡∞Æ‡∞ø. \"\n",
    "                      \"‡∞™‡∞Ç‡∞ó‡∞æ‡∞Ç‡∞ó‡±ç ‡∞∏‡∞∞‡±ã‡∞µ‡∞∞‡±ç, ‡∞®‡±Å‡∞¨‡±ç‡∞∞‡∞æ ‡∞µ‡±ç‡∞Ø‡∞æ‡∞≤‡±Ä, ‡∞¨‡±Å‡∞¶‡±ç‡∞ß ‡∞Æ‡∞†‡∞æ‡∞≤‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£‡∞≤‡±Å. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞ü‡±ç‡∞∞‡±Ü‡∞ï‡±ç‡∞ï‡∞ø‡∞Ç‡∞ó‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡∞æ‡∞π‡∞∏ ‡∞Ø‡∞æ‡∞§‡±ç‡∞∞‡∞≤‡∞ï‡±Å ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞ø ‡∞ö‡±Ü‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞¶‡∞ø.\"),\n",
    "        \"tags\": [\"‡∞π‡∞ø‡∞Æ‡∞æ‡∞≤‡∞Ø‡∞æ‡∞≤‡±Å\", \"‡∞≤‡±á‡∞π‡±ç\", \"‡∞ü‡±ç‡∞∞‡±Ü‡∞ï‡±ç‡∞ï‡∞ø‡∞Ç‡∞ó‡±ç\"]\n",
    "    },\n",
    "    \n",
    "    # Cities\n",
    "    \"‡∞Æ‡±Å‡∞Ç‡∞¨‡±à\": {\n",
    "        \"description\": (\"‡∞Æ‡±Å‡∞Ç‡∞¨‡±à ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂ ‡∞Ü‡∞∞‡±ç‡∞•‡∞ø‡∞ï ‡∞∞‡∞æ‡∞ú‡∞ß‡∞æ‡∞®‡∞ø. \"\n",
    "                      \"‡∞ó‡±á‡∞ü‡±ç‡∞µ‡±á ‡∞Ü‡∞´‡±ç ‡∞á‡∞Ç‡∞°‡∞ø‡∞Ø‡∞æ, ‡∞Æ‡∞∞‡±Ä‡∞®‡±ç ‡∞°‡±ç‡∞∞‡±à‡∞µ‡±ç, ‡∞¨‡∞æ‡∞≤‡±Ä‡∞µ‡±Å‡∞°‡±ç ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£‡∞≤‡±Å. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂‡∞Ç‡∞≤‡±ã‡∞®‡∞ø ‡∞Ö‡∞§‡±ç‡∞Ø‡∞ß‡∞ø‡∞ï ‡∞ú‡∞®‡∞∏‡∞æ‡∞Ç‡∞¶‡±ç‡∞∞‡∞§ ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø‡∞® ‡∞®‡∞ó‡∞∞‡∞Ç.\"),\n",
    "        \"tags\": [\"‡∞¨‡∞æ‡∞≤‡±Ä‡∞µ‡±Å‡∞°‡±ç\", \"‡∞ó‡±á‡∞ü‡±ç‡∞µ‡±á\", \"‡∞Ü‡∞∞‡±ç‡∞•‡∞ø‡∞ï ‡∞∞‡∞æ‡∞ú‡∞ß‡∞æ‡∞®‡∞ø\"]\n",
    "    },\n",
    "    \"‡∞¨‡±Ü‡∞Ç‡∞ó‡∞≥‡±Ç‡∞∞‡±Å\": {\n",
    "        \"description\": (\"‡∞¨‡±Ü‡∞Ç‡∞ó‡∞≥‡±Ç‡∞∞‡±Å‡∞®‡±Å '‡∞∏‡∞ø‡∞≤‡∞ø‡∞ï‡∞æ‡∞®‡±ç ‡∞µ‡±ç‡∞Ø‡∞æ‡∞≤‡±Ä ‡∞Ü‡∞´‡±ç ‡∞á‡∞Ç‡∞°‡∞ø‡∞Ø‡∞æ' ‡∞Ö‡∞®‡∞ø ‡∞™‡∞ø‡∞≤‡±Å‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂ ‡∞ê‡∞ü‡±Ä ‡∞∞‡∞æ‡∞ú‡∞ß‡∞æ‡∞®‡∞ø. \"\n",
    "                      \"‡∞≤‡∞æ‡∞≤‡±ç ‡∞¨‡∞æ‡∞ó‡±ç, ‡∞¨‡±Ü‡∞Ç‡∞ó‡∞≥‡±Ç‡∞∞‡±Å ‡∞™‡±ç‡∞Ø‡∞æ‡∞≤‡±Ü‡∞∏‡±ç, ‡∞ê‡∞é‡∞∏‡±ç‚Äå‡∞ï‡±Ü‡∞Ü‡∞®‡±ç ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£‡∞≤‡±Å.\"),\n",
    "        \"tags\": [\"‡∞ê‡∞ü‡±Ä\", \"‡∞∏‡∞ø‡∞≤‡∞ø‡∞ï‡∞æ‡∞®‡±ç ‡∞µ‡±ç‡∞Ø‡∞æ‡∞≤‡±Ä\", \"‡∞ó‡∞æ‡∞∞‡±ç‡∞°‡±Ü‡∞®‡±ç ‡∞∏‡∞ø‡∞ü‡±Ä\"]\n",
    "    },\n",
    "    \n",
    "    # Pilgrimage\n",
    "    \"‡∞Ö‡∞Æ‡±É‡∞§‡∞∏‡∞∞‡±ç\": {\n",
    "        \"description\": (\"‡∞Ö‡∞Æ‡±É‡∞§‡∞∏‡∞∞‡±ç ‡∞≤‡±ã‡∞®‡∞ø ‡∞∏‡±ç‡∞µ‡∞∞‡±ç‡∞£‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞Ç (‡∞ó‡±ã‡∞≤‡±ç‡∞°‡±Ü‡∞®‡±ç ‡∞ü‡±Ü‡∞Ç‡∞™‡±Å‡∞≤‡±ç) ‡∞∏‡∞ø‡∞ï‡±ç‡∞ï‡±Å ‡∞Æ‡∞§‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞™‡∞µ‡∞ø‡∞§‡±ç‡∞∞ ‡∞∏‡±ç‡∞•‡∞≤‡∞Ç. \"\n",
    "                      \"‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞≤‡∞Ç‡∞ó‡∞∞‡±ç (‡∞∏‡∞æ‡∞Æ‡±Ç‡∞π‡∞ø‡∞ï ‡∞≠‡±ã‡∞ú‡∞®‡∞Ç) ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞ø ‡∞ö‡±Ü‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞¶‡∞ø. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞™‡∞Ç‡∞ú‡∞æ‡∞¨‡±ç ‡∞∞‡∞æ‡∞∑‡±ç‡∞ü‡±ç‡∞∞‡∞Ç‡∞≤‡±ã ‡∞â‡∞Ç‡∞¶‡∞ø.\"),\n",
    "        \"tags\": [\"‡∞ó‡±ã‡∞≤‡±ç‡∞°‡±Ü‡∞®‡±ç ‡∞ü‡±Ü‡∞Ç‡∞™‡±Å‡∞≤‡±ç\", \"‡∞∏‡∞ø‡∞ï‡±ç‡∞ï‡±Å‡∞≤‡±Å\", \"‡∞≤‡∞Ç‡∞ó‡∞∞‡±ç\"]\n",
    "    },\n",
    "    \"‡∞∞‡∞æ‡∞Æ‡±á‡∞∂‡±ç‡∞µ‡∞∞‡∞Ç\": {\n",
    "        \"description\": (\"‡∞∞‡∞æ‡∞Æ‡±á‡∞∂‡±ç‡∞µ‡∞∞‡∞Ç ‡∞§‡∞Æ‡∞ø‡∞≥‡∞®‡∞æ‡∞°‡±Å‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® ‡∞™‡∞µ‡∞ø‡∞§‡±ç‡∞∞ ‡∞π‡∞ø‡∞Ç‡∞¶‡±Ç ‡∞§‡±Ä‡∞∞‡±ç‡∞•‡∞Ø‡∞æ‡∞§‡±ç‡∞∞‡∞æ ‡∞ï‡±á‡∞Ç‡∞¶‡±ç‡∞∞‡∞Ç. \"\n",
    "                      \"‡∞∞‡∞æ‡∞Æ‡∞®‡∞æ‡∞•‡∞∏‡±ç‡∞µ‡∞æ‡∞Æ‡∞ø ‡∞¶‡±á‡∞µ‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞Ç ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£. \"\n",
    "                      \"‡∞π‡∞ø‡∞Ç‡∞¶‡±Ç ‡∞™‡±Å‡∞∞‡∞æ‡∞£‡∞æ‡∞≤ ‡∞™‡±ç‡∞∞‡∞ï‡∞æ‡∞∞‡∞Ç ‡∞∂‡±ç‡∞∞‡±Ä‡∞∞‡∞æ‡∞Æ‡±Å‡∞°‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡±á ‡∞∞‡∞æ‡∞µ‡∞£‡±Å‡∞®‡∞ø ‡∞µ‡∞¶‡±ç‡∞¶‡∞ï‡±Å ‡∞∏‡±á‡∞§‡±Å‡∞µ‡±Å ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞æ‡∞°‡±Å.\"),\n",
    "        \"tags\": [\"‡∞∏‡±á‡∞§‡±Å\", \"‡∞∞‡∞æ‡∞Æ‡∞®‡∞æ‡∞•‡∞∏‡±ç‡∞µ‡∞æ‡∞Æ‡∞ø\", \"‡∞§‡±Ä‡∞∞‡±ç‡∞•‡∞Ø‡∞æ‡∞§‡±ç‡∞∞\"]\n",
    "    },\n",
    "    \n",
    "    # Added more places\n",
    "    \"‡∞π‡±à‡∞¶‡∞∞‡∞æ‡∞¨‡∞æ‡∞¶‡±ç\": {\n",
    "        \"description\": (\"‡∞π‡±à‡∞¶‡∞∞‡∞æ‡∞¨‡∞æ‡∞¶‡±ç ‡∞§‡±Ü‡∞≤‡∞Ç‡∞ó‡∞æ‡∞£ ‡∞∞‡∞æ‡∞ú‡∞ß‡∞æ‡∞®‡∞ø. \"\n",
    "                      \"‡∞ö‡∞æ‡∞∞‡±ç‡∞Æ‡∞ø‡∞®‡∞æ‡∞∞‡±ç, ‡∞ó‡±ã‡∞≤‡±ç‡∞ï‡±ä‡∞Ç‡∞° ‡∞ï‡±ã‡∞ü, ‡∞∞‡∞æ‡∞Æ‡±ã‡∞ú‡±Ä ‡∞´‡∞ø‡∞≤‡±ç‡∞Æ‡±ç ‡∞∏‡∞ø‡∞ü‡±Ä ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£‡∞≤‡±Å. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂ ‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞æ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ê‡∞ü‡±Ä ‡∞π‡∞¨‡±ç.\"),\n",
    "        \"tags\": [\"‡∞ö‡∞æ‡∞∞‡±ç‡∞Æ‡∞ø‡∞®‡∞æ‡∞∞‡±ç\", \"‡∞¨‡∞ø‡∞∞‡±ç‡∞Ø‡∞æ‡∞®‡±Ä\", \"‡∞ü‡±Ü‡∞ï‡±ç ‡∞∏‡∞ø‡∞ü‡±Ä\"]\n",
    "    },\n",
    "    \"‡∞ú‡±à‡∞™‡±Ç‡∞∞‡±ç\": {\n",
    "        \"description\": (\"‡∞ú‡±à‡∞™‡±Ç‡∞∞‡±ç‡∞®‡±Å '‡∞™‡∞ø‡∞Ç‡∞ï‡±ç ‡∞∏‡∞ø‡∞ü‡±Ä' ‡∞Ö‡∞®‡∞ø ‡∞™‡∞ø‡∞≤‡±Å‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å. \"\n",
    "                      \"‡∞π‡∞µ‡∞æ ‡∞Æ‡∞π‡∞≤‡±ç, ‡∞Ö‡∞Ç‡∞¨‡∞∞‡±ç ‡∞ï‡±ã‡∞ü, ‡∞ú‡∞Ç‡∞§‡∞∞‡±ç ‡∞Æ‡∞Ç‡∞§‡∞∞‡±ç ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£‡∞≤‡±Å. \"\n",
    "                      \"‡∞á‡∞¶‡∞ø ‡∞∞‡∞æ‡∞ú‡∞∏‡±ç‡∞•‡∞æ‡∞®‡±ç ‡∞∞‡∞æ‡∞ú‡∞ß‡∞æ‡∞®‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ó‡±ã‡∞≤‡±ç‡∞°‡±Ü‡∞®‡±ç ‡∞ü‡±ç‡∞∞‡∞Ø‡∞æ‡∞Ç‡∞ó‡∞ø‡∞≤‡±ç ‡∞≤‡±ã ‡∞≠‡∞æ‡∞ó‡∞Ç.\"),\n",
    "        \"tags\": [\"‡∞™‡∞ø‡∞Ç‡∞ï‡±ç ‡∞∏‡∞ø‡∞ü‡±Ä\", \"‡∞π‡∞µ‡∞æ ‡∞Æ‡∞π‡∞≤‡±ç\", \"‡∞∞‡∞æ‡∞ú‡∞∏‡±ç‡∞•‡∞æ‡∞®‡±ç\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "def generate_telugu_response(user_input):\n",
    "    \"\"\"Generate Telugu responses using knowledge base or generative model\"\"\"\n",
    "    # Check knowledge base first\n",
    "    for place, info in knowledge_base.items():\n",
    "        if place.lower() in user_input.lower() or any(tag in user_input for tag in info[\"tags\"]):\n",
    "            return info[\"description\"]\n",
    "    \n",
    "    # Generate response if not in knowledge base\n",
    "    try:\n",
    "        prompt = f\"‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø: {user_input}\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=150,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return clean_telugu_text(response.split(\":\")[-1].strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞è‡∞∞‡±ç‡∞™‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.\"\n",
    "\n",
    "def clean_telugu_text(text):\n",
    "    \"\"\"Clean and format Telugu text output\"\"\"\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.replace(' .', '‡•§').replace('.', '‡•§')\n",
    "    if not text.endswith(('‡∞Ç', '‡±Å', '‡∞ø', '‡±Ä', '‡∞æ', '‡±ã', '‡±Ç', '‡±ç', '?')):\n",
    "        text += '‡•§'\n",
    "    return text\n",
    "\n",
    "# Create widgets\n",
    "output_area = widgets.Output()\n",
    "chat_history = widgets.HTML(value=\"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç</h2>\")\n",
    "input_text = widgets.Text(placeholder='‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞ü‡±à‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø...', layout=widgets.Layout(width='80%'))\n",
    "send_button = widgets.Button(description='‡∞™‡∞Ç‡∞™‡∞ø‡∞Ç‡∞ö‡±Å', button_style='success')\n",
    "clear_button = widgets.Button(description='‡∞ï‡±ç‡∞≤‡∞ø‡∞Ø‡∞∞‡±ç', button_style='warning')\n",
    "\n",
    "def on_send(b):\n",
    "    user_input = input_text.value.strip()\n",
    "    if not user_input:\n",
    "        with output_area:\n",
    "            print(\"‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞è‡∞¶‡±ã ‡∞ü‡±à‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø\")\n",
    "        return\n",
    "    \n",
    "    # Add user message\n",
    "    chat_history.value += f\"<div style='margin:10px;padding:10px;background:#e6f3ff;border-radius:5px'><b>‡∞Æ‡±Ä‡∞∞‡±Å:</b> {user_input}</div>\"\n",
    "    input_text.value = ''\n",
    "    \n",
    "    with output_area:\n",
    "        print(\"‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞∏‡±ç‡∞™‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Æ‡±Å...\")\n",
    "        try:\n",
    "            response = generate_telugu_response(user_input)\n",
    "            chat_history.value += f\"<div style='margin:10px;padding:10px;background:#e6ffe6;border-radius:5px'><b>‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡±Å:</b> {response}</div>\"\n",
    "        except Exception as e:\n",
    "            chat_history.value += f\"<div style='margin:10px;padding:10px;background:#ffebee;border-radius:5px'><b>‡∞≤‡±ã‡∞™‡∞Ç:</b> {str(e)}</div>\"\n",
    "        finally:\n",
    "            clear_output()\n",
    "\n",
    "def on_clear(b):\n",
    "    chat_history.value = \"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç</h2>\"\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "\n",
    "# Connect buttons\n",
    "send_button.on_click(on_send)\n",
    "clear_button.on_click(on_clear)\n",
    "\n",
    "# Display interface\n",
    "display(widgets.VBox([\n",
    "    chat_history,\n",
    "    widgets.HBox([input_text, send_button]),\n",
    "    clear_button,\n",
    "    output_area\n",
    "]))\n",
    "\n",
    "print(\"‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø! ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡±Å ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chari\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Using device: cpu\n",
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbc1606240f487993df4200d21868b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<div style='font-family:Arial;'><h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞ö‡∞æ‡∞ü‡±ç\\u200c‡∞¨‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import pyaudio\n",
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from gtts import gTTS\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import io\n",
    "import warnings\n",
    "from IPython.display import display, clear_output, Audio\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the knowledge base FIRST - before any functions that use it\n",
    "knowledge_base = {\n",
    "    \"tirupati\": {\n",
    "        \"description\": \"‡∞§‡∞ø‡∞∞‡±Å‡∞™‡∞§‡∞ø‡∞≤‡±ã‡∞®‡∞ø ‡∞∂‡±ç‡∞∞‡±Ä ‡∞µ‡±á‡∞Ç‡∞ï‡∞ü‡±á‡∞∂‡±ç‡∞µ‡∞∞ ‡∞∏‡±ç‡∞µ‡∞æ‡∞Æ‡∞ø ‡∞Ü‡∞≤‡∞Ø‡∞Ç ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß ‡∞π‡∞ø‡∞Ç‡∞¶‡±Ç ‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞Ç. ‡∞á‡∞¶‡∞ø ‡∞Ü‡∞Ç‡∞ß‡±ç‡∞∞‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡±ç ‡∞≤‡±ã‡∞®‡∞ø ‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤ ‡∞™‡∞∞‡±ç‡∞µ‡∞§‡∞æ‡∞≤ ‡∞Æ‡±Ä‡∞¶ ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞∏‡∞Ç‡∞µ‡∞§‡±ç‡∞∏‡∞∞‡∞Ç ‡∞≤‡∞ï‡±ç‡∞∑‡∞≤‡∞æ‡∞¶‡∞ø ‡∞≠‡∞ï‡±ç‡∞§‡±Å‡∞≤‡±Å ‡∞¶‡∞∞‡±ç‡∞∂‡∞®‡∞Ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞µ‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å.\",\n",
    "        \"tags\": [\"‡∞§‡∞ø‡∞∞‡±Å‡∞™‡∞§‡∞ø\", \"‡∞µ‡±á‡∞Ç‡∞ï‡∞ü‡±á‡∞∂‡±ç‡∞µ‡∞∞\", \"‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤\", \"‡∞Ü‡∞Ç‡∞ß‡±ç‡∞∞‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡±ç\"]\n",
    "    },\n",
    "    \"hyderabad\": {\n",
    "        \"description\": \"‡∞π‡±à‡∞¶‡∞∞‡∞æ‡∞¨‡∞æ‡∞¶‡±ç ‡∞≤‡±ã ‡∞ö‡∞æ‡∞∞‡±ç‡∞Æ‡∞ø‡∞®‡∞æ‡∞∞‡±ç, ‡∞ó‡±ã‡∞≤‡±ç‡∞ï‡±ä‡∞Ç‡∞° ‡∞ï‡±ã‡∞ü, ‡∞∞‡∞æ‡∞Æ‡±ã‡∞ú‡±Ä ‡∞´‡∞ø‡∞≤‡±ç‡∞Æ‡±ç ‡∞∏‡∞ø‡∞ü‡±Ä ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£‡∞≤‡±Å. ‡∞π‡±à‡∞¶‡∞∞‡∞æ‡∞¨‡∞æ‡∞¶‡±ç ‡∞§‡±Ü‡∞≤‡∞Ç‡∞ó‡∞æ‡∞£ ‡∞∞‡∞æ‡∞∑‡±ç‡∞ü‡±ç‡∞∞ ‡∞∞‡∞æ‡∞ú‡∞ß‡∞æ‡∞®‡∞ø.\",\n",
    "        \"tags\": [\"‡∞π‡±à‡∞¶‡∞∞‡∞æ‡∞¨‡∞æ‡∞¶‡±ç\", \"‡∞ö‡∞æ‡∞∞‡±ç‡∞Æ‡∞ø‡∞®‡∞æ‡∞∞‡±ç\", \"‡∞ó‡±ã‡∞≤‡±ç‡∞ï‡±ä‡∞Ç‡∞°\", \"‡∞∞‡∞æ‡∞Æ‡±ã‡∞ú‡±Ä ‡∞´‡∞ø‡∞≤‡±ç‡∞Æ‡±ç ‡∞∏‡∞ø‡∞ü‡±Ä\", \"‡∞§‡±Ü‡∞≤‡∞Ç‡∞ó‡∞æ‡∞£\"]\n",
    "    },\n",
    "    \"vijayawada\": {\n",
    "        \"description\": \"‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞æ‡∞° ‡∞Ü‡∞Ç‡∞ß‡±ç‡∞∞‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡±ç ‡∞≤‡±ã‡∞®‡∞ø ‡∞í‡∞ï ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞®‡∞ó‡∞∞‡∞Ç. ‡∞á‡∞¶‡∞ø ‡∞ï‡±É‡∞∑‡±ç‡∞£‡∞æ ‡∞®‡∞¶‡∞ø ‡∞í‡∞°‡±ç‡∞°‡±Å‡∞® ‡∞â‡∞Ç‡∞¶‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡±ç‡∞Ø‡∞æ‡∞™‡∞æ‡∞∞, ‡∞µ‡∞æ‡∞£‡∞ø‡∞ú‡±ç‡∞Ø ‡∞ï‡±á‡∞Ç‡∞¶‡±ç‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞ø ‡∞ö‡±Ü‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞ï‡∞®‡∞ï‡∞¶‡±Å‡∞∞‡±ç‡∞ó ‡∞Æ‡∞≤‡±ç‡∞≤‡±á‡∞∂‡±ç‡∞µ‡∞∞ ‡∞∏‡±ç‡∞µ‡∞æ‡∞Æ‡∞ø ‡∞Ü‡∞≤‡∞Ø‡∞Ç ‡∞á‡∞ï‡±ç‡∞ï‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£.\",\n",
    "        \"tags\": [\"‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞æ‡∞°\", \"‡∞ï‡±É‡∞∑‡±ç‡∞£‡∞æ\", \"‡∞ï‡∞®‡∞ï‡∞¶‡±Å‡∞∞‡±ç‡∞ó\", \"‡∞Ü‡∞Ç‡∞ß‡±ç‡∞∞‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡±ç\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "try:\n",
    "    # Embedding model\n",
    "    embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device=device)\n",
    "    \n",
    "    # Speech recognition - Using Whisper medium model for better Telugu recognition\n",
    "    asr = pipeline(\"automatic-speech-recognition\", \n",
    "                  model=\"openai/whisper-medium\",\n",
    "                  device=0 if torch.cuda.is_available() else -1)\n",
    "    \n",
    "    # Text generation\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\").to(device)\n",
    "    \n",
    "    print(\"Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    raise\n",
    "\n",
    "# Pre-compute embeddings for all knowledge base items\n",
    "for key in knowledge_base:\n",
    "    knowledge_base[key][\"embedding\"] = embedder.encode(knowledge_base[key][\"description\"])\n",
    "\n",
    "def clean_telugu_text(text):\n",
    "    \"\"\"Clean and normalize Telugu text\"\"\"\n",
    "    import re\n",
    "    text = re.sub(r'[^\\u0C00-\\u0C7F\\s.,!?]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "def retrieve_knowledge(query, top_k=2):\n",
    "    \"\"\"Retrieve relevant knowledge\"\"\"\n",
    "    cleaned_query = clean_telugu_text(query)\n",
    "    \n",
    "    # First try exact matches with knowledge base keys\n",
    "    if cleaned_query.lower() in [k.lower() for k in knowledge_base.keys()]:\n",
    "        return [knowledge_base[cleaned_query.lower()][\"description\"]]\n",
    "    \n",
    "    # Then try tag matches\n",
    "    matched_items = []\n",
    "    for key in knowledge_base:\n",
    "        item = knowledge_base[key]\n",
    "        if any(tag.lower() in cleaned_query.lower() for tag in item[\"tags\"]):\n",
    "            matched_items.append(item[\"description\"])\n",
    "    \n",
    "    if matched_items:\n",
    "        return matched_items[:top_k]\n",
    "    \n",
    "    # Semantic search fallback\n",
    "    query_embedding = embedder.encode(cleaned_query)\n",
    "    similarities = []\n",
    "    \n",
    "    for key in knowledge_base:\n",
    "        item = knowledge_base[key]\n",
    "        sim = cosine_similarity([query_embedding], [item[\"embedding\"]])[0][0]\n",
    "        similarities.append((sim, item[\"description\"]))\n",
    "    \n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "    return [text for (sim, text) in similarities[:top_k] if sim > 0.5]\n",
    "\n",
    "def generate_telugu_response(user_input):\n",
    "    \"\"\"Generate context-aware Telugu response.\"\"\"\n",
    "    cleaned_input = clean_telugu_text(user_input)\n",
    "    context = retrieve_knowledge(cleaned_input)\n",
    "    \n",
    "    if context:\n",
    "        if len(context) == 1:\n",
    "            return context[0]\n",
    "        prompt = f\"‡∞∏‡∞Ç‡∞¶‡∞∞‡±ç‡∞≠‡∞Ç: {' '.join(context)}\\n\\n‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®: {cleaned_input}\\n‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç:\"\n",
    "    else:\n",
    "        prompt = f\"‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø: {cleaned_input}\"\n",
    "    \n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=150,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return clean_telugu_text(response.split(\"‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç:\")[-1].strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Generation error: {e}\")\n",
    "        return \"‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞≤‡±á‡∞ï‡∞™‡±ã‡∞Ø‡∞æ‡∞®‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞∞‡±ã‡∞∏‡∞æ‡∞∞‡∞ø ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.\"\n",
    "\n",
    "def text_to_speech(text, lang='te'):\n",
    "    \"\"\"Convert text to speech\"\"\"\n",
    "    cleaned_text = clean_telugu_text(text)\n",
    "    if not cleaned_text or cleaned_text.strip() == \"\":\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        tts = gTTS(text=cleaned_text, lang=lang, slow=False)\n",
    "        audio_file = io.BytesIO()\n",
    "        tts.write_to_fp(audio_file)\n",
    "        audio_file.seek(0)\n",
    "        return audio_file\n",
    "    except Exception as e:\n",
    "        print(f\"TTS Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def record_audio(duration=5, sample_rate=16000):\n",
    "    \"\"\"Record audio with better error handling\"\"\"\n",
    "    try:\n",
    "        chunk = 1024\n",
    "        format = pyaudio.paInt16\n",
    "        channels = 1\n",
    "        p = pyaudio.PyAudio()\n",
    "\n",
    "        # Check available devices\n",
    "        info = p.get_default_input_device_info()\n",
    "        if info['maxInputChannels'] == 0:\n",
    "            raise ValueError(\"‡∞Æ‡±à‡∞ï‡±ç‡∞∞‡±ã‡∞´‡±ã‡∞®‡±ç ‡∞ï‡∞®‡±Å‡∞ó‡±ä‡∞®‡∞¨‡∞°‡∞≤‡±á‡∞¶‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡±Ä ‡∞Æ‡±à‡∞ï‡±ç‡∞∞‡±ã‡∞´‡±ã‡∞®‡±ç ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.\")\n",
    "\n",
    "        stream = p.open(format=format,\n",
    "                        channels=channels,\n",
    "                        rate=sample_rate,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=chunk,\n",
    "                        input_device_index=info['index'])\n",
    "        \n",
    "        print(\"‡∞∞‡∞ø‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡∞ø‡∞Ç‡∞ó‡±ç ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞Æ‡±à‡∞Ç‡∞¶‡∞ø... ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø\")\n",
    "        frames = []\n",
    "        \n",
    "        for _ in range(0, int(sample_rate / chunk * duration)):\n",
    "            data = stream.read(chunk, exception_on_overflow=False)\n",
    "            frames.append(data)\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        # Check if audio was recorded\n",
    "        if len(frames) == 0:\n",
    "            raise ValueError(\"‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞∞‡∞ø‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡±ç ‡∞ï‡∞æ‡∞≤‡±á‡∞¶‡±Å\")\n",
    "\n",
    "        wav_buffer = io.BytesIO()\n",
    "        with wave.open(wav_buffer, 'wb') as wf:\n",
    "            wf.setnchannels(channels)\n",
    "            wf.setsampwidth(p.get_sample_size(format))\n",
    "            wf.setframerate(sample_rate)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "        \n",
    "        wav_buffer.seek(0)\n",
    "        return wav_buffer\n",
    "    except Exception as e:\n",
    "        print(f\"Recording error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create widgets\n",
    "output_area = widgets.Output()\n",
    "chat_history = widgets.HTML(\n",
    "    value=\"<div style='font-family:Arial;'>\"\n",
    "          \"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç</h2>\"\n",
    "          \"<p>‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡±à‡∞ï‡±ç‡∞∞‡±ã‡∞´‡±ã‡∞®‡±ç‚Äå‡∞®‡±Å ‡∞Ö‡∞®‡±Å‡∞Æ‡∞§‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Ç‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø</p>\"\n",
    "          \"</div>\"\n",
    ")\n",
    "\n",
    "record_button = widgets.Button(\n",
    "    description=\"‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø (5 ‡∞∏‡±Ü‡∞ï‡∞®‡±ç‡∞≤‡±Å)\", \n",
    "    button_style='success',\n",
    "    icon='microphone',\n",
    "    layout=widgets.Layout(width='200px', height='50px')\n",
    ")\n",
    "\n",
    "clear_button = widgets.Button(\n",
    "    description=\"‡∞ï‡±ç‡∞≤‡∞ø‡∞Ø‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø\", \n",
    "    button_style='warning',\n",
    "    icon='trash',\n",
    "    layout=widgets.Layout(width='150px', height='50px')\n",
    ")\n",
    "\n",
    "button_box = widgets.HBox([record_button, clear_button], \n",
    "                         layout=widgets.Layout(justify_content='center'))\n",
    "\n",
    "main_container = widgets.VBox([\n",
    "    chat_history,\n",
    "    button_box,\n",
    "    output_area\n",
    "], layout=widgets.Layout(\n",
    "    width='80%', \n",
    "    margin='0 auto',\n",
    "    padding='20px',\n",
    "    border='2px solid #1f618d',\n",
    "    border_radius='10px',\n",
    "    box_shadow='0 4px 8px 0 rgba(0,0,0,0.2)'\n",
    "))\n",
    "\n",
    "def on_record(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        try:\n",
    "            print(\"‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø 5 ‡∞∏‡±Ü‡∞ï‡∞®‡±ç‡∞≤ ‡∞™‡∞æ‡∞ü‡±Å ‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Ç‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø...\")\n",
    "            audio_buffer = record_audio()\n",
    "            \n",
    "            if audio_buffer is None:\n",
    "                raise ValueError(\"‡∞Æ‡±à‡∞ï‡±ç‡∞∞‡±ã‡∞´‡±ã‡∞®‡±ç ‡∞™‡∞®‡∞ø‡∞ö‡±á‡∞Ø‡∞°‡∞Ç ‡∞≤‡±á‡∞¶‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞∞‡∞ø‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡±ç ‡∞ï‡∞æ‡∞≤‡±á‡∞¶‡±Å.\")\n",
    "                \n",
    "            print(\"‡∞Æ‡±Ä ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞∞‡∞ø‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡∞ø‡∞Ç‡∞ó‡±ç ‡∞™‡±ç‡∞≤‡±á ‡∞Ö‡∞µ‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø...\")\n",
    "            display(Audio(audio_buffer.read(), autoplay=True))\n",
    "            audio_buffer.seek(0)\n",
    "            \n",
    "            print(\"‡∞Æ‡±Ä ‡∞Æ‡∞æ‡∞ü‡∞≤‡∞®‡±Å ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡±Å‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Æ‡±Å...\")\n",
    "            audio_data = np.frombuffer(audio_buffer.read(), dtype=np.int16)\n",
    "            \n",
    "            # Convert and normalize audio data\n",
    "            audio_data = audio_data.astype(np.float32) / 32768.0\n",
    "            \n",
    "            # Use ASR with Telugu language setting\n",
    "            transcript = asr(audio_data, generate_kwargs={\"language\": \"telugu\"})[\"text\"]\n",
    "            \n",
    "            cleaned_transcript = clean_telugu_text(transcript)\n",
    "            print(f\"‡∞ó‡±Å‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç: {cleaned_transcript}\")\n",
    "            \n",
    "            if not cleaned_transcript.strip():\n",
    "                raise ValueError(\"‡∞Æ‡∞æ‡∞ü‡∞≤‡±Å ‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Ç‡∞ó‡∞æ ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞≤‡±á‡∞¶‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞∞‡±ã‡∞∏‡∞æ‡∞∞‡∞ø ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.\")\n",
    "                \n",
    "            print(f\"‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®: {cleaned_transcript}\")\n",
    "            \n",
    "            response = generate_telugu_response(cleaned_transcript)\n",
    "            print(f\"‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç: {response}\")\n",
    "            \n",
    "            audio_response = text_to_speech(response)\n",
    "            if audio_response:\n",
    "                print(\"‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞™‡±ç‡∞≤‡±á ‡∞Ö‡∞µ‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø...\")\n",
    "                display(Audio(audio_response.read(), autoplay=True))\n",
    "            \n",
    "            chat_history.value += f\"\"\"\n",
    "            <div style='font-family:Arial; margin:10px 0; padding:10px; border-radius:5px; background-color:#f8f9f9;'>\n",
    "                <div style='color:#1a5276; font-weight:bold;'>‡∞Æ‡±Ä‡∞∞‡±Å:</div>\n",
    "                <div style='margin-left:15px;'>{cleaned_transcript}</div>\n",
    "                <div style='color:#27ae60; font-weight:bold; margin-top:5px;'>‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç:</div>\n",
    "                <div style='margin-left:15px;'>{response}</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã ‡∞≤‡±ã‡∞™‡∞Ç: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            chat_history.value += f\"\"\"\n",
    "            <div style='font-family:Arial; color:#c0392b; margin:10px 0; padding:10px; background-color:#fadbd8; border-radius:5px;'>\n",
    "                {error_msg}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "def on_clear(b):\n",
    "    chat_history.value = \"<div style='font-family:Arial;'>\" \\\n",
    "                        \"<h2 style='color:#1f618d'>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç</h2>\" \\\n",
    "                        \"<p>‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡±à‡∞ï‡±ç‡∞∞‡±ã‡∞´‡±ã‡∞®‡±ç‚Äå‡∞®‡±Å ‡∞Ö‡∞®‡±Å‡∞Æ‡∞§‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Ç‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø</p>\" \\\n",
    "                        \"</div>\"\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "\n",
    "# Connect buttons\n",
    "record_button.on_click(on_record)\n",
    "clear_button.on_click(on_clear)\n",
    "\n",
    "# Display interface\n",
    "display(main_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a81062816a54f06b1077236e67651d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c234236b804df588c305cc839ec433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h2 style='color:#1f618d'>‡∞ö‡∞ø‡∞§‡±ç‡∞∞ ‡∞µ‡∞ø‡∞µ‡∞∞‡∞£ ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡∞∞‡±ç</h2>\"), HBox(children=(FileUpload(val‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞æ‡∞≤‡∞ï‡±Å ‡∞µ‡∞ø‡∞µ‡∞∞‡∞£‡∞≤‡±Å ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø! ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç ‡∞Ö‡∞™‡±ç‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡∞ø ‡∞¨‡∞ü‡∞®‡±ç ‡∞®‡±ä‡∞ï‡±ç‡∞ï‡∞Ç‡∞°‡∞ø\n"
     ]
    }
   ],
   "source": [
    "# Image Captioning Bot with Deep Translator for Telugu\n",
    "#!pip install -q transformers torch pillow ipywidgets deep-translator\n",
    "#!apt-get install -qq libgl1-mesa-glx\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline, BlipForConditionalGeneration, BlipProcessor\n",
    "from deep_translator import GoogleTranslator\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize translator\n",
    "translator = GoogleTranslator(source='en', target='te')\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "try:\n",
    "    # Image captioning model\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    caption_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "    print(\"Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    raise\n",
    "\n",
    "def generate_caption(image):\n",
    "    \"\"\"Generate English caption for an image and translate to Telugu\"\"\"\n",
    "    try:\n",
    "        # Convert to RGB if needed\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "            \n",
    "        # Generate English caption\n",
    "        inputs = processor(image, return_tensors=\"pt\").to(device)\n",
    "        outputs = caption_model.generate(**inputs, max_new_tokens=50)\n",
    "        english_caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Translate to Telugu using Deep Translator\n",
    "        telugu_caption = translator.translate(english_caption)\n",
    "        \n",
    "        return english_caption, telugu_caption\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Captioning error: {e}\")\n",
    "        return \"Could not generate caption\", \"‡∞µ‡∞ø‡∞µ‡∞∞‡∞£‡∞®‡±Å ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞≤‡±á‡∞ï‡∞™‡±ã‡∞Ø‡∞æ‡∞Æ‡±Å\"\n",
    "\n",
    "def image_to_base64(image):\n",
    "    \"\"\"Convert image to base64 for display\"\"\"\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "# Create widgets\n",
    "output_area = widgets.Output()\n",
    "chat_history = widgets.HTML(value=\"<h2 style='color:#1f618d'>‡∞ö‡∞ø‡∞§‡±ç‡∞∞ ‡∞µ‡∞ø‡∞µ‡∞∞‡∞£ ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡∞∞‡±ç</h2>\")\n",
    "upload_button = widgets.FileUpload(\n",
    "    description=\"‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç ‡∞Ö‡∞™‡±ç‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø\",\n",
    "    accept='image/*',\n",
    "    multiple=False\n",
    ")\n",
    "generate_button = widgets.Button(description=\"‡∞µ‡∞ø‡∞µ‡∞∞‡∞£‡∞®‡±Å ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡±Å\", button_style=\"success\")\n",
    "clear_button = widgets.Button(description=\"‡∞ï‡±ç‡∞≤‡∞ø‡∞Ø‡∞∞‡±ç\", button_style=\"warning\")\n",
    "\n",
    "def on_generate(b):\n",
    "    if not upload_button.value:\n",
    "        with output_area:\n",
    "            print(\"‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å ‡∞í‡∞ï ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç ‡∞Ö‡∞™‡±ç‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø\")\n",
    "        return\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        print(\"‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Æ‡±Å...\")\n",
    "        \n",
    "        # Get uploaded image\n",
    "        uploaded = upload_button.value[0]\n",
    "        image_bytes = uploaded['content']\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        \n",
    "        # Display image\n",
    "        display(image)\n",
    "        \n",
    "        # Generate and display captions\n",
    "        english_caption, telugu_caption = generate_caption(image)\n",
    "        chat_history.value += f\"\"\"\n",
    "        <div style='margin:10px; padding:10px; border:1px solid #eee; border-radius:5px'>\n",
    "            <img src='data:image/png;base64,{image_to_base64(image)}' width='300'/>\n",
    "            <p><b>English:</b> {english_caption}</p>\n",
    "            <p><b>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å:</b> {telugu_caption}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        print(f\"‡∞µ‡∞ø‡∞µ‡∞∞‡∞£ ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø!\")\n",
    "\n",
    "def on_clear(b):\n",
    "    chat_history.value = \"<h2 style='color:#1f618d'>‡∞ö‡∞ø‡∞§‡±ç‡∞∞ ‡∞µ‡∞ø‡∞µ‡∞∞‡∞£ ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡∞∞‡±ç</h2>\"\n",
    "    upload_button.value = []\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "\n",
    "# Connect buttons\n",
    "generate_button.on_click(on_generate)\n",
    "clear_button.on_click(on_clear)\n",
    "\n",
    "# Display interface\n",
    "display(widgets.VBox([\n",
    "    chat_history,\n",
    "    widgets.HBox([upload_button, generate_button, clear_button]),\n",
    "    output_area\n",
    "]))\n",
    "\n",
    "print(\"‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞æ‡∞≤‡∞ï‡±Å ‡∞µ‡∞ø‡∞µ‡∞∞‡∞£‡∞≤‡±Å ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø! ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç ‡∞Ö‡∞™‡±ç‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡∞ø ‡∞¨‡∞ü‡∞®‡±ç ‡∞®‡±ä‡∞ï‡±ç‡∞ï‡∞Ç‡∞°‡∞ø\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
